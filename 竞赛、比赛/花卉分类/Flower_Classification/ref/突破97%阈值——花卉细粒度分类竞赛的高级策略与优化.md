**策略 A：采用锐度感知最小化 (Sharpness-Aware Minimization - SAM) 优化器**

- **问题诊断**：在低数据量

    

  下训练的高精度模型（97%），极有可能陷入了损失函数的“狭窄、陡峭的深谷”（Sharp Minima）。这意味着模型对训练数据产生了*过度拟合*——训练集上损失极低，但只要测试数据有微小扰动，预测就会“翻车”到高损失区域。

- **解决方案**：SAM优化器的工作原理是，它不只是寻找损失*最低*的点，而是寻找损失*最平坦*（Flat Minima）的区域。一个“平坦”的区域意味着，即使测试数据有轻微变化，模型依然处于低损失区域，从而具有更强的*泛化能力*。

- **做法**：替换当前的`AdamW`优化器。SAM通常作为“包装器”使用（例如`torch_sam`库）。它会使每个训练步骤的计算量增加近一倍（因为它需要进行两次前向/后向传播来“探测”周围的锐度），但它在FGVC和低数据量任务上的泛化能力提升是经过SOTA研究验证的。





**策略 B：标签平滑 (Label Smoothing)**

- **做法**：如果尚未采用，请立即在`nn.CrossEntropyLoss`中启用。

  - `loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)`

- **价值**：对于100类分类

    

  ，这可以防止模型变得过分自信（例如预测概率为1.0），这是一种过拟合。它强迫模型为其他类别分配一点点概率（例如，真实标签为``，平滑后变为`[0.001, 0.001, 0.901, 0.001]`），这能提高校准度（calibration）和泛化能力。



**策略 C：损失函数调优 (Focal Loss)**

- **分析**：剩余的3%错误是“难例样本”。标准交叉熵对所有样本一视同仁。`Focal Loss`会动态地“降低”那些模型已经能正确分类（例如99%置信度）的“简单”样本的损失权重，同时“提升”那些模型搞不定（例如40%置信度）的“困难”样本的权重。
- **做法**：尝试用Focal Loss替换Cross-Entropy，尤其是在训练的后半段，用于“攻坚”难例。





### 3.3 K-Fold模型的最终融合 (Full-Data Fine-tuning)



**现状分析**： K-Fold交叉验证（例如5-Fold）意味着每个模型都只用了80%的数据进行训练。

**做法**：

1. 完成所有的K-Fold实验和HPO搜索，确定了最佳的模型架构和超参数。
2. 加载在K-Fold中表现*最好*的那个Fold的模型权重（作为最佳起点）。
3. 将*所有*训练数据（100%）合并（不再需要验证集）。
4. 使用这些数据，以一个非常低的学习率（例如最终LR的1/10），对模型进行最后1-2个epochs的微调。

**预期**： 模型将“看到”它从未见过的最后20%的数据，这有可能带来最后的0.05% - 0.2%的提升，确保



### K-Fold模型的最终融合 (Full-Data Fine-tuning)



**现状分析**： K-Fold交叉验证（例如5-Fold）意味着每个模型都只用了80%的数据进行训练。

**做法**：

1. 完成所有的K-Fold实验和HPO搜索，确定了最佳的模型架构和超参数。
2. 加载在K-Fold中表现*最好*的那个Fold的模型权重（作为最佳起点）。
3. 将*所有*训练数据（100%）合并（不再需要验证集）。
4. 使用这些数据，以一个非常低的学习率（例如最终LR的1/10），对模型进行最后1-2个epochs的微调。

**预期**： 模型将“看到”它从未见过的最后20%的数据，这有可能带来最后的0.05% - 0.2%的提升，确保



